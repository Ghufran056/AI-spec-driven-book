---
id: 6.3-grasp-planning-strategies
title: Grasp Planning Strategies
sidebar_label: 6.3 - Grasp Planning Strategies
---

# Grasp Planning Strategies

## Learning Objectives

By the end of this lesson, you will be able to:
- Understand the fundamental principles of robotic grasp planning
- Compare different grasp planning approaches and their applications
- Implement basic grasp planning algorithms for simple objects
- Evaluate grasp quality and stability metrics
- Integrate grasp planning with object recognition and manipulation systems
- Recognize the challenges and limitations of grasp planning in real-world scenarios

## Introduction

Grasp planning is a critical component of robotic manipulation that determines how a robot should approach and grasp an object to successfully pick it up and manipulate it. The process involves selecting appropriate contact points on the object, determining the optimal approach direction, and calculating the necessary grasp configuration for the robot's end-effector. Effective grasp planning must consider object geometry, material properties, robot kinematics, and environmental constraints to ensure stable and reliable grasping.

Grasp planning algorithms range from analytical methods that compute optimal grasps based on geometric and physical models to learning-based approaches that leverage experience and data to select effective grasps. The choice of approach depends on factors such as object complexity, available sensing, computational resources, and task requirements. Modern grasp planning systems often combine multiple strategies to handle diverse objects and scenarios.

The challenge in grasp planning lies in the need to balance multiple competing objectives: achieving a stable grasp, avoiding collisions with the environment, maintaining manipulability for subsequent tasks, and ensuring that the grasp can be executed within the robot's physical constraints. Successful grasp planning requires understanding both the geometric properties of objects and the physics of contact mechanics.

## Main Theory

### 1. Antipodal Grasps
Grasps where contact points are positioned opposite to each other on the object, providing stable force closure for cylindrical or elongated objects.

### 2. Enveloping Grasps
Grasps that wrap around the object using multiple contact points, suitable for irregularly shaped objects or when high stability is required.

### 3. Pinch Grasps
Precision grasps using fingertips to grasp small objects, typically involving two or three contact points for fine manipulation.

### 4. Force Closure vs Form Closure
Force closure relies on friction and applied forces to maintain grasp stability, while form closure depends on geometric constraints alone.

### 5. Grasp Quality Metrics
Quantitative measures used to evaluate the quality of potential grasps, including grasp wrench space, contact stability, and robustness to perturbations.

### 6. Sampling-Based Grasp Planning
Approaches that sample potential grasp configurations and evaluate them using quality metrics, suitable for complex objects and scenarios.

```
Grasp Planning Process:

[Object Model] → [Grasp Candidate Generation] → [Quality Evaluation] → [Grasp Selection] → [Execution]
      ↑                      ↑                          ↑                   ↑             ↑
[Geometry] ←→ [Kinematics] ←→ [Stability Metrics] ←→ [Optimization] ←→ [Constraints]
```

## Examples

### Example: Basic Grasp Planning Algorithm
```python
import numpy as np
from scipy.spatial.distance import cdist
from typing import List, Tuple, Optional
import math

class GraspPlanner:
    """Basic grasp planning system for robotic manipulation"""

    def __init__(self):
        self.approach_directions = [
            np.array([0, 0, 1]),    # From above
            np.array([1, 0, 0]),    # From side (positive X)
            np.array([-1, 0, 0]),   # From side (negative X)
            np.array([0, 1, 0]),    # From side (positive Y)
            np.array([0, -1, 0]),   # From side (negative Y)
        ]

    def generate_grasp_candidates(self, object_points: np.ndarray,
                                num_candidates: int = 50) -> List[dict]:
        """
        Generate potential grasp candidates based on object geometry
        """
        candidates = []

        # Calculate object bounding box to understand dimensions
        min_coords = np.min(object_points, axis=0)
        max_coords = np.max(object_points, axis=0)
        dimensions = max_coords - min_coords

        # Sample points on the object surface
        surface_points = self.sample_surface_points(object_points, num_candidates)

        for point in surface_points:
            for approach_dir in self.approach_directions:
                # Calculate grasp direction (perpendicular to approach)
                grasp_dir = np.cross(approach_dir, np.array([0, 0, 1]))
                if np.linalg.norm(grasp_dir) < 0.1:  # Handle parallel case
                    grasp_dir = np.array([1, 0, 0])

                grasp_dir = grasp_dir / np.linalg.norm(grasp_dir)

                # Create grasp candidate
                candidate = {
                    'position': point,
                    'approach_direction': approach_dir,
                    'grasp_direction': grasp_dir,
                    'quality': 0.0
                }

                # Evaluate grasp quality
                candidate['quality'] = self.evaluate_grasp_quality(
                    object_points, candidate
                )

                candidates.append(candidate)

        return candidates

    def sample_surface_points(self, object_points: np.ndarray,
                            num_points: int) -> List[np.ndarray]:
        """
        Sample points on the object surface for potential grasp locations
        """
        # For this example, we'll randomly sample points from the point cloud
        # In practice, this would use more sophisticated surface sampling
        if len(object_points) <= num_points:
            return [np.array(p) for p in object_points]

        indices = np.random.choice(len(object_points), num_points, replace=False)
        return [np.array(object_points[i]) for i in indices]

    def evaluate_grasp_quality(self, object_points: np.ndarray,
                             grasp_candidate: dict) -> float:
        """
        Evaluate the quality of a grasp candidate based on geometric properties
        """
        pos = grasp_candidate['position']
        approach = grasp_candidate['approach_direction']
        grasp_dir = grasp_candidate['grasp_direction']

        # Check if approach direction is free of obstacles
        # (In practice, this would check against environment geometry)
        approach_clear = self.is_approach_clear(object_points, pos, approach)

        # Calculate grasp width (distance between potential contact points)
        grasp_width = self.estimate_grasp_width(object_points, pos, grasp_dir)

        # Calculate geometric properties for quality assessment
        quality = 0.0

        if approach_clear and 0.01 < grasp_width < 0.2:  # Reasonable grasp width
            # Prefer grasps at object edges or features
            edge_score = self.calculate_edge_score(object_points, pos)
            quality = 0.3 * approach_clear + 0.4 * edge_score + 0.3 * (1.0 / grasp_width)

        return min(quality, 1.0)  # Clamp to [0, 1]

    def is_approach_clear(self, object_points: np.ndarray,
                         position: np.ndarray, approach_dir: np.ndarray) -> bool:
        """
        Check if approach direction is clear of object geometry
        """
        # Sample points along the approach direction
        for dist in np.linspace(0.01, 0.05, 5):  # Check 1-5cm from surface
            test_point = position + approach_dir * dist
            # Find closest point on object
            distances = np.linalg.norm(object_points - test_point, axis=1)
            if np.min(distances) < 0.01:  # Within 1cm
                return False  # Approach blocked

        return True

    def estimate_grasp_width(self, object_points: np.ndarray,
                           position: np.ndarray, grasp_dir: np.ndarray) -> float:
        """
        Estimate the width of the object in the grasp direction
        """
        # Project points along grasp direction
        projections = np.dot(object_points, grasp_dir)
        min_proj = np.min(projections)
        max_proj = np.max(projections)

        return max_proj - min_proj

    def calculate_edge_score(self, object_points: np.ndarray,
                           position: np.ndarray) -> float:
        """
        Calculate score based on how "edge-like" the grasp location is
        """
        # Find neighboring points
        distances = np.linalg.norm(object_points - position, axis=1)
        neighbors = object_points[distances < 0.02]  # Points within 2cm

        if len(neighbors) < 3:
            return 0.0

        # Calculate local curvature/surface properties
        # Simple approach: look for regions with high point density variation
        cov_matrix = np.cov(neighbors.T)
        eigenvalues = np.linalg.eigvals(cov_matrix)
        eigenvalues = np.sort(eigenvalues)

        # Prefer locations with one small eigenvalue (planar) or all similar (corner)
        if eigenvalues[0] < 0.1 * eigenvalues[2]:  # Planar region
            return 0.8
        elif abs(eigenvalues[0] - eigenvalues[2]) < 0.1:  # Corner-like
            return 0.9
        else:  # In-between
            return 0.5

    def select_best_grasp(self, candidates: List[dict],
                         min_quality: float = 0.5) -> Optional[dict]:
        """
        Select the best grasp from candidates based on quality
        """
        valid_candidates = [c for c in candidates if c['quality'] >= min_quality]
        if not valid_candidates:
            return None

        # Return the candidate with highest quality
        return max(valid_candidates, key=lambda x: x['quality'])

# Example usage
def grasp_planning_example():
    planner = GraspPlanner()

    # Create a sample object point cloud (a simple cube for demonstration)
    cube_points = []
    for x in np.linspace(-0.05, 0.05, 10):
        for y in np.linspace(-0.05, 0.05, 10):
            for z in np.linspace(-0.05, 0.05, 10):
                # Only include surface points to make it more realistic
                if (abs(x) == 0.05 or abs(y) == 0.05 or abs(z) == 0.05):
                    cube_points.append([x, y, z])

    object_points = np.array(cube_points)

    # Generate grasp candidates
    candidates = planner.generate_grasp_candidates(object_points, num_candidates=100)

    # Select best grasp
    best_grasp = planner.select_best_grasp(candidates)

    if best_grasp:
        print(f"Best grasp found:")
        print(f"  Position: {best_grasp['position']}")
        print(f"  Approach: {best_grasp['approach_direction']}")
        print(f"  Quality: {best_grasp['quality']:.3f}")
    else:
        print("No suitable grasp found")

if __name__ == "__main__":
    grasp_planning_example()
```

### Example: Grasp Quality Evaluation Metrics
```python
import numpy as np
from typing import List, Tuple
import math

class GraspQualityEvaluator:
    """Evaluates grasp quality using multiple metrics"""

    def __init__(self, friction_coeff=0.8):
        self.friction_coeff = friction_coeff

    def force_closure_metric(self, contact_points: List[np.ndarray],
                           contact_normals: List[np.ndarray]) -> float:
        """
        Evaluate force closure - ability to resist arbitrary wrenches
        """
        if len(contact_points) < 2:
            return 0.0

        # For 2D case: check if contact normals point toward each other
        if len(contact_points[0]) == 2:
            # Calculate angle between contact normals
            n1 = contact_normals[0] / np.linalg.norm(contact_normals[0])
            n2 = contact_normals[1] / np.linalg.norm(contact_normals[1])

            # Check if normals point toward each other (angle > 90°)
            dot_product = np.dot(n1, n2)
            if dot_product < -0.1:  # Pointing roughly toward each other
                return 1.0
            else:
                return 0.0

        # For 3D case: more complex force closure analysis
        # This is a simplified version - full analysis requires polyhedral cone computation
        if len(contact_points) >= 4:
            # Multiple contacts increase chance of force closure
            return min(1.0, len(contact_points) * 0.25)
        else:
            return 0.0

    def grasp_width_metric(self, grasp_width: float,
                          min_width: float = 0.01,
                          max_width: float = 0.15) -> float:
        """
        Evaluate grasp width appropriateness
        """
        if min_width <= grasp_width <= max_width:
            # Score based on how close to optimal width
            optimal = (min_width + max_width) / 2
            deviation = abs(grasp_width - optimal) / (max_width - min_width)
            return max(0.0, 1.0 - deviation)
        else:
            return 0.0

    def contact_stability_metric(self, object_points: np.ndarray,
                               contact_points: List[np.ndarray],
                               grasp_axis: np.ndarray) -> float:
        """
        Evaluate stability based on contact distribution
        """
        if len(contact_points) < 2:
            return 0.0

        # Calculate how well contacts distribute along grasp axis
        projections = [np.dot(cp, grasp_axis) for cp in contact_points]
        min_proj, max_proj = min(projections), max(projections)

        # Prefer contacts that span a reasonable distance
        span = max_proj - min_proj
        if span > 0.02:  # At least 2cm span
            return min(1.0, span / 0.1)  # Cap at 10cm span
        else:
            return 0.5 * span / 0.02  # Lower score for small span

    def wrench_space_metric(self, contact_points: List[np.ndarray],
                          contact_forces: List[np.ndarray]) -> float:
        """
        Evaluate the wrench space that can be resisted by the grasp
        """
        # Simplified metric based on contact distribution
        if len(contact_points) < 2:
            return 0.0

        # Calculate the volume of the grasp wrench space (simplified)
        # This would be more complex in a real implementation
        total_force_magnitude = sum(np.linalg.norm(f) for f in contact_forces)
        return min(1.0, total_force_magnitude / 100.0)  # Normalize

    def evaluate_comprehensive_grasp_quality(self, object_points: np.ndarray,
                                           contact_points: List[np.ndarray],
                                           contact_normals: List[np.ndarray],
                                           grasp_width: float,
                                           grasp_axis: np.ndarray) -> dict:
        """
        Evaluate comprehensive grasp quality using multiple metrics
        """
        metrics = {}

        # Calculate individual metrics
        metrics['force_closure'] = self.force_closure_metric(contact_points, contact_normals)
        metrics['grasp_width'] = self.grasp_width_metric(grasp_width)
        metrics['contact_stability'] = self.contact_stability_metric(
            object_points, contact_points, grasp_axis
        )

        # Create dummy contact forces for wrench space metric
        dummy_forces = [n * 10.0 for n in contact_normals]  # 10N in normal direction
        metrics['wrench_space'] = self.wrench_space_metric(contact_points, dummy_forces)

        # Calculate overall quality as weighted average
        weights = {
            'force_closure': 0.4,
            'grasp_width': 0.2,
            'contact_stability': 0.2,
            'wrench_space': 0.2
        }

        overall_quality = sum(metrics[metric] * weights[metric] for metric in weights)

        return {
            'metrics': metrics,
            'weights': weights,
            'overall_quality': overall_quality
        }

# Example usage
def quality_evaluation_example():
    evaluator = GraspQualityEvaluator()

    # Example grasp configuration
    object_points = np.random.rand(100, 3) * 0.1  # Random object points
    contact_points = [
        np.array([0.02, 0.0, 0.0]),
        np.array([-0.02, 0.0, 0.0])
    ]
    contact_normals = [
        np.array([-1.0, 0.0, 0.0]),  # Pointing inward
        np.array([1.0, 0.0, 0.0])    # Pointing inward
    ]
    grasp_width = 0.04  # 4cm
    grasp_axis = np.array([1.0, 0.0, 0.0])

    quality_result = evaluator.evaluate_comprehensive_grasp_quality(
        object_points, contact_points, contact_normals, grasp_width, grasp_axis
    )

    print("Grasp Quality Evaluation:")
    for metric, value in quality_result['metrics'].items():
        print(f"  {metric}: {value:.3f}")

    print(f"Overall Quality: {quality_result['overall_quality']:.3f}")

if __name__ == "__main__":
    quality_evaluation_example()
```

### Example: Integration with Robot Kinematics
```python
import numpy as np
from typing import List, Tuple, Optional
from dataclasses import dataclass

@dataclass
class GraspPose:
    """Represents a complete grasp pose with approach, pre-grasp, and grasp positions"""
    approach_pose: np.ndarray  # 3D position + orientation
    pre_grasp_pose: np.ndarray
    grasp_pose: np.ndarray
    grasp_quality: float
    grasp_type: str  # 'power', 'pinch', 'suction', etc.

class KinematicGraspPlanner:
    """Grasp planner that considers robot kinematics and constraints"""

    def __init__(self, robot_workspace_limits: dict):
        self.workspace_limits = robot_workspace_limits
        self.max_joint_velocity = 1.0  # rad/s
        self.max_joint_torque = 100.0  # Nm

    def plan_grasp_with_kinematics(self, object_position: np.ndarray,
                                 object_orientation: np.ndarray,
                                 grasp_candidate: dict) -> Optional[GraspPose]:
        """
        Plan grasp poses considering robot kinematics and workspace constraints
        """
        # Calculate grasp pose based on object pose and grasp direction
        grasp_pose = self.calculate_grasp_pose(object_position, object_orientation, grasp_candidate)

        # Check if grasp pose is within workspace
        if not self.is_in_workspace(grasp_pose[:3]):  # Check position only
            return None

        # Calculate approach pose (offset along approach direction)
        approach_offset = grasp_candidate['approach_direction'] * 0.1  # 10cm approach
        approach_pose = grasp_pose.copy()
        approach_pose[:3] += approach_offset

        # Check if approach pose is also within workspace
        if not self.is_in_workspace(approach_pose[:3]):
            # Try alternative approach direction
            alt_approach = grasp_candidate['approach_direction'] * -0.1
            approach_pose[:3] = grasp_pose[:3] + alt_approach
            if not self.is_in_workspace(approach_pose[:3]):
                return None

        # Calculate pre-grasp pose (slightly before grasp)
        pre_grasp_pose = grasp_pose.copy()
        pre_grasp_offset = grasp_candidate['approach_direction'] * 0.02  # 2cm before grasp
        pre_grasp_pose[:3] += pre_grasp_offset

        # Check joint limits would be satisfied (simplified check)
        if not self.would_exceed_joint_limits(approach_pose, grasp_pose):
            return GraspPose(
                approach_pose=approach_pose,
                pre_grasp_pose=pre_grasp_pose,
                grasp_pose=grasp_pose,
                grasp_quality=grasp_candidate['quality'],
                grasp_type=self.determine_grasp_type(grasp_candidate)
            )

        return None

    def calculate_grasp_pose(self, obj_pos: np.ndarray, obj_rot: np.ndarray,
                           grasp_candidate: dict) -> np.ndarray:
        """
        Calculate full 6D grasp pose from object pose and grasp parameters
        """
        # Calculate position: object position + offset in grasp direction
        grasp_pos = obj_pos + grasp_candidate['position_offset']

        # Calculate orientation: align gripper with grasp direction
        grasp_dir = grasp_candidate['grasp_direction']
        approach_dir = grasp_candidate['approach_direction']

        # Create rotation matrix from approach and grasp directions
        z_axis = approach_dir / np.linalg.norm(approach_dir)
        y_axis = grasp_dir / np.linalg.norm(grasp_dir)
        x_axis = np.cross(y_axis, z_axis)
        x_axis = x_axis / np.linalg.norm(x_axis)
        y_axis = np.cross(z_axis, x_axis)  # Recompute to ensure orthogonality

        rotation_matrix = np.column_stack([x_axis, y_axis, z_axis])

        # Convert to quaternion (simplified)
        # In practice, use proper quaternion conversion
        pose = np.zeros(7)  # [x, y, z, qx, qy, qz, qw]
        pose[:3] = grasp_pos

        # Convert rotation matrix to quaternion
        trace = np.trace(rotation_matrix)
        if trace > 0:
            s = 0.5 / np.sqrt(trace + 1.0)
            pose[6] = 0.25 / s  # w
            pose[3] = (rotation_matrix[2, 1] - rotation_matrix[1, 2]) * s  # x
            pose[4] = (rotation_matrix[0, 2] - rotation_matrix[2, 0]) * s  # y
            pose[5] = (rotation_matrix[1, 0] - rotation_matrix[0, 1]) * s  # z
        else:
            if rotation_matrix[0, 0] > rotation_matrix[1, 1] and rotation_matrix[0, 0] > rotation_matrix[2, 2]:
                s = 2.0 * np.sqrt(1.0 + rotation_matrix[0, 0] - rotation_matrix[1, 1] - rotation_matrix[2, 2])
                pose[3] = 0.25 * s
                pose[4] = (rotation_matrix[0, 1] + rotation_matrix[1, 0]) / s
                pose[5] = (rotation_matrix[0, 2] + rotation_matrix[2, 0]) / s
                pose[6] = (rotation_matrix[2, 1] - rotation_matrix[1, 2]) / s
            elif rotation_matrix[1, 1] > rotation_matrix[2, 2]:
                s = 2.0 * np.sqrt(1.0 + rotation_matrix[1, 1] - rotation_matrix[0, 0] - rotation_matrix[2, 2])
                pose[3] = (rotation_matrix[0, 1] + rotation_matrix[1, 0]) / s
                pose[4] = 0.25 * s
                pose[5] = (rotation_matrix[1, 2] + rotation_matrix[2, 1]) / s
                pose[6] = (rotation_matrix[0, 2] - rotation_matrix[2, 0]) / s
            else:
                s = 2.0 * np.sqrt(1.0 + rotation_matrix[2, 2] - rotation_matrix[0, 0] - rotation_matrix[1, 1])
                pose[3] = (rotation_matrix[0, 2] + rotation_matrix[2, 0]) / s
                pose[4] = (rotation_matrix[1, 2] + rotation_matrix[2, 1]) / s
                pose[5] = 0.25 * s
                pose[6] = (rotation_matrix[1, 0] - rotation_matrix[0, 1]) / s

        return pose

    def is_in_workspace(self, position: np.ndarray) -> bool:
        """Check if position is within robot workspace"""
        x, y, z = position
        limits = self.workspace_limits
        return (limits['x_min'] <= x <= limits['x_max'] and
                limits['y_min'] <= y <= limits['y_max'] and
                limits['z_min'] <= z <= limits['z_max'])

    def would_exceed_joint_limits(self, start_pose: np.ndarray,
                                end_pose: np.ndarray) -> bool:
        """Check if trajectory between poses would exceed joint limits"""
        # Simplified check - in practice, this would involve inverse kinematics
        # and trajectory verification
        distance = np.linalg.norm(end_pose[:3] - start_pose[:3])
        # Assume this distance can be achieved within joint limits for this example
        return False

    def determine_grasp_type(self, grasp_candidate: dict) -> str:
        """Determine appropriate grasp type based on object and grasp properties"""
        # This would use more sophisticated logic in practice
        grasp_width = grasp_candidate.get('grasp_width', 0.1)

        if grasp_width < 0.03:  # Small objects
            return 'pinch'
        elif grasp_width < 0.08:  # Medium objects
            return 'power'
        else:  # Large objects
            return 'enveloping'

# Example usage
def kinematic_integration_example():
    # Define robot workspace limits
    workspace_limits = {
        'x_min': -1.0, 'x_max': 1.0,
        'y_min': -1.0, 'y_max': 1.0,
        'z_min': 0.0,  'z_max': 1.5
    }

    planner = KinematicGraspPlanner(workspace_limits)

    # Example object and grasp candidate
    object_pos = np.array([0.5, 0.0, 0.2])
    object_rot = np.eye(3)  # Identity rotation

    grasp_candidate = {
        'position_offset': np.array([0.0, 0.0, 0.0]),
        'grasp_direction': np.array([0.0, 1.0, 0.0]),
        'approach_direction': np.array([0.0, 0.0, 1.0]),
        'quality': 0.8,
        'grasp_width': 0.05
    }

    grasp_pose = planner.plan_grasp_with_kinematics(object_pos, object_rot, grasp_candidate)

    if grasp_pose:
        print(f"Valid grasp planned:")
        print(f"  Approach: [{grasp_pose.approach_pose[:3]}]")
        print(f"  Grasp: [{grasp_pose.grasp_pose[:3]}]")
        print(f"  Quality: {grasp_pose.grasp_quality:.3f}")
        print(f"  Type: {grasp_pose.grasp_type}")
    else:
        print("Could not plan valid grasp within kinematic constraints")

if __name__ == "__main__":
    kinematic_integration_example()
```

## Practical Notes

- Consider object material properties and fragility in grasp planning
- Validate grasp plans with physical simulation before execution
- Implement regrasping strategies for failed grasp attempts
- Account for sensor noise and uncertainty in object pose estimation
- Test grasp planning under various environmental conditions
- Plan for computational efficiency in real-time applications
- Implement safety checks to prevent damage to objects or robot

## Summary

Grasp planning is a complex task that requires understanding of object geometry, robot kinematics, and physical interactions. Successful grasp planning systems must balance multiple objectives including grasp stability, kinematic feasibility, and task requirements. Modern approaches combine analytical methods with learning-based techniques to handle diverse objects and scenarios in real-world manipulation tasks.

## Glossary

- **Grasp Planning**: Process of determining how to grasp an object with a robot hand
- **Force Closure**: Grasp condition where applied forces can resist arbitrary external wrenches
- **Form Closure**: Grasp relying on geometric constraints rather than friction forces
- **Grasp Wrench Space**: Set of external forces and torques a grasp can resist
- **Contact Points**: Locations where robot fingers make contact with object
- **Approach Direction**: Direction robot approaches object before grasping
- **Grasp Quality Metric**: Quantitative measure of grasp stability and effectiveness
- **Antipodal Grasp**: Grasp with contact points on opposite sides of object
- **Pinch Grasp**: Precision grasp using fingertips for small objects
- **Power Grasp**: Grasp using fingers wrapped around object for strength
- **Enveloping Grasp**: Grasp wrapping around object with multiple contact points
- **Grasp Stability**: Ability of grasp to maintain contact under disturbances

## Quick Quiz

1. What is the main difference between force closure and form closure grasps?
   A) Force closure uses more contact points
   B) Force closure relies on friction and applied forces, form closure on geometric constraints
   C) Form closure is only for spherical objects
   D) There is no difference between them

2. What does "grasp wrench space" refer to?
   A) The physical space around the object
   B) The set of external forces and torques a grasp can resist
   C) The workspace of the robot arm
   D) The area where grasping is possible

3. Which grasp type is typically used for precision manipulation of small objects?
   A) Power grasp
   B) Enveloping grasp
   C) Pinch grasp
   D) Suction grasp

4. What is an antipodal grasp?
   A) A grasp with contact points on the same side
   B) A grasp with contact points on opposite sides of the object
   C) A grasp using only one finger
   D) A grasp that cannot resist forces

5. Why is it important to consider robot kinematics in grasp planning?
   A) To make the robot move faster
   B) To ensure the robot can physically reach the planned grasp pose
   C) To reduce computational requirements
   D) To improve sensor accuracy

**Answers:**
1. B) Force closure relies on friction and applied forces, form closure on geometric constraints
2. B) The set of external forces and torques a grasp can resist
3. C) Pinch grasp
4. B) A grasp with contact points on opposite sides of the object
5. B) To ensure the robot can physically reach the planned grasp pose