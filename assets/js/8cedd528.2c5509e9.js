"use strict";(globalThis.webpackChunkai_driven_book=globalThis.webpackChunkai_driven_book||[]).push([[8880],{6372:(n,e,a)=>{a.r(e),a.d(e,{assets:()=>p,contentTitle:()=>o,default:()=>d,frontMatter:()=>s,metadata:()=>i,toc:()=>c});const i=JSON.parse('{"id":"chapter6/6.3-grasp-planning-strategies","title":"Grasp Planning Strategies","description":"Learning Objectives","source":"@site/docs/chapter6/6.3-grasp-planning-strategies.mdx","sourceDirName":"chapter6","slug":"/chapter6/6.3-grasp-planning-strategies","permalink":"/AI-spec-driven-book/docs/chapter6/6.3-grasp-planning-strategies","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/chapter6/6.3-grasp-planning-strategies.mdx","tags":[],"version":"current","frontMatter":{"id":"6.3-grasp-planning-strategies","title":"Grasp Planning Strategies","sidebar_label":"6.3 - Grasp Planning Strategies"},"sidebar":"tutorialSidebar","previous":{"title":"6.2 - Object Recognition for Manipulation","permalink":"/AI-spec-driven-book/docs/chapter6/6.2-object-recognition-for-manipulation"},"next":{"title":"6.4 - Manipulation Pipeline","permalink":"/AI-spec-driven-book/docs/chapter6/6.4-manipulation-pipeline"}}');var t=a(4848),r=a(8453);const s={id:"6.3-grasp-planning-strategies",title:"Grasp Planning Strategies",sidebar_label:"6.3 - Grasp Planning Strategies"},o="Grasp Planning Strategies",p={},c=[{value:"Learning Objectives",id:"learning-objectives",level:2},{value:"Introduction",id:"introduction",level:2},{value:"Main Theory",id:"main-theory",level:2},{value:"1. Antipodal Grasps",id:"1-antipodal-grasps",level:3},{value:"2. Enveloping Grasps",id:"2-enveloping-grasps",level:3},{value:"3. Pinch Grasps",id:"3-pinch-grasps",level:3},{value:"4. Force Closure vs Form Closure",id:"4-force-closure-vs-form-closure",level:3},{value:"5. Grasp Quality Metrics",id:"5-grasp-quality-metrics",level:3},{value:"6. Sampling-Based Grasp Planning",id:"6-sampling-based-grasp-planning",level:3},{value:"Examples",id:"examples",level:2},{value:"Example: Basic Grasp Planning Algorithm",id:"example-basic-grasp-planning-algorithm",level:3},{value:"Example: Grasp Quality Evaluation Metrics",id:"example-grasp-quality-evaluation-metrics",level:3},{value:"Example: Integration with Robot Kinematics",id:"example-integration-with-robot-kinematics",level:3},{value:"Practical Notes",id:"practical-notes",level:2},{value:"Summary",id:"summary",level:2},{value:"Glossary",id:"glossary",level:2},{value:"Quick Quiz",id:"quick-quiz",level:2}];function l(n){const e={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,r.R)(),...n.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(e.header,{children:(0,t.jsx)(e.h1,{id:"grasp-planning-strategies",children:"Grasp Planning Strategies"})}),"\n",(0,t.jsx)(e.h2,{id:"learning-objectives",children:"Learning Objectives"}),"\n",(0,t.jsx)(e.p,{children:"By the end of this lesson, you will be able to:"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"Understand the fundamental principles of robotic grasp planning"}),"\n",(0,t.jsx)(e.li,{children:"Compare different grasp planning approaches and their applications"}),"\n",(0,t.jsx)(e.li,{children:"Implement basic grasp planning algorithms for simple objects"}),"\n",(0,t.jsx)(e.li,{children:"Evaluate grasp quality and stability metrics"}),"\n",(0,t.jsx)(e.li,{children:"Integrate grasp planning with object recognition and manipulation systems"}),"\n",(0,t.jsx)(e.li,{children:"Recognize the challenges and limitations of grasp planning in real-world scenarios"}),"\n"]}),"\n",(0,t.jsx)(e.h2,{id:"introduction",children:"Introduction"}),"\n",(0,t.jsx)(e.p,{children:"Grasp planning is a critical component of robotic manipulation that determines how a robot should approach and grasp an object to successfully pick it up and manipulate it. The process involves selecting appropriate contact points on the object, determining the optimal approach direction, and calculating the necessary grasp configuration for the robot's end-effector. Effective grasp planning must consider object geometry, material properties, robot kinematics, and environmental constraints to ensure stable and reliable grasping."}),"\n",(0,t.jsx)(e.p,{children:"Grasp planning algorithms range from analytical methods that compute optimal grasps based on geometric and physical models to learning-based approaches that leverage experience and data to select effective grasps. The choice of approach depends on factors such as object complexity, available sensing, computational resources, and task requirements. Modern grasp planning systems often combine multiple strategies to handle diverse objects and scenarios."}),"\n",(0,t.jsx)(e.p,{children:"The challenge in grasp planning lies in the need to balance multiple competing objectives: achieving a stable grasp, avoiding collisions with the environment, maintaining manipulability for subsequent tasks, and ensuring that the grasp can be executed within the robot's physical constraints. Successful grasp planning requires understanding both the geometric properties of objects and the physics of contact mechanics."}),"\n",(0,t.jsx)(e.h2,{id:"main-theory",children:"Main Theory"}),"\n",(0,t.jsx)(e.h3,{id:"1-antipodal-grasps",children:"1. Antipodal Grasps"}),"\n",(0,t.jsx)(e.p,{children:"Grasps where contact points are positioned opposite to each other on the object, providing stable force closure for cylindrical or elongated objects."}),"\n",(0,t.jsx)(e.h3,{id:"2-enveloping-grasps",children:"2. Enveloping Grasps"}),"\n",(0,t.jsx)(e.p,{children:"Grasps that wrap around the object using multiple contact points, suitable for irregularly shaped objects or when high stability is required."}),"\n",(0,t.jsx)(e.h3,{id:"3-pinch-grasps",children:"3. Pinch Grasps"}),"\n",(0,t.jsx)(e.p,{children:"Precision grasps using fingertips to grasp small objects, typically involving two or three contact points for fine manipulation."}),"\n",(0,t.jsx)(e.h3,{id:"4-force-closure-vs-form-closure",children:"4. Force Closure vs Form Closure"}),"\n",(0,t.jsx)(e.p,{children:"Force closure relies on friction and applied forces to maintain grasp stability, while form closure depends on geometric constraints alone."}),"\n",(0,t.jsx)(e.h3,{id:"5-grasp-quality-metrics",children:"5. Grasp Quality Metrics"}),"\n",(0,t.jsx)(e.p,{children:"Quantitative measures used to evaluate the quality of potential grasps, including grasp wrench space, contact stability, and robustness to perturbations."}),"\n",(0,t.jsx)(e.h3,{id:"6-sampling-based-grasp-planning",children:"6. Sampling-Based Grasp Planning"}),"\n",(0,t.jsx)(e.p,{children:"Approaches that sample potential grasp configurations and evaluate them using quality metrics, suitable for complex objects and scenarios."}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{children:"Grasp Planning Process:\n\n[Object Model] \u2192 [Grasp Candidate Generation] \u2192 [Quality Evaluation] \u2192 [Grasp Selection] \u2192 [Execution]\n      \u2191                      \u2191                          \u2191                   \u2191             \u2191\n[Geometry] \u2190\u2192 [Kinematics] \u2190\u2192 [Stability Metrics] \u2190\u2192 [Optimization] \u2190\u2192 [Constraints]\n"})}),"\n",(0,t.jsx)(e.h2,{id:"examples",children:"Examples"}),"\n",(0,t.jsx)(e.h3,{id:"example-basic-grasp-planning-algorithm",children:"Example: Basic Grasp Planning Algorithm"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:'import numpy as np\nfrom scipy.spatial.distance import cdist\nfrom typing import List, Tuple, Optional\nimport math\n\nclass GraspPlanner:\n    """Basic grasp planning system for robotic manipulation"""\n\n    def __init__(self):\n        self.approach_directions = [\n            np.array([0, 0, 1]),    # From above\n            np.array([1, 0, 0]),    # From side (positive X)\n            np.array([-1, 0, 0]),   # From side (negative X)\n            np.array([0, 1, 0]),    # From side (positive Y)\n            np.array([0, -1, 0]),   # From side (negative Y)\n        ]\n\n    def generate_grasp_candidates(self, object_points: np.ndarray,\n                                num_candidates: int = 50) -> List[dict]:\n        """\n        Generate potential grasp candidates based on object geometry\n        """\n        candidates = []\n\n        # Calculate object bounding box to understand dimensions\n        min_coords = np.min(object_points, axis=0)\n        max_coords = np.max(object_points, axis=0)\n        dimensions = max_coords - min_coords\n\n        # Sample points on the object surface\n        surface_points = self.sample_surface_points(object_points, num_candidates)\n\n        for point in surface_points:\n            for approach_dir in self.approach_directions:\n                # Calculate grasp direction (perpendicular to approach)\n                grasp_dir = np.cross(approach_dir, np.array([0, 0, 1]))\n                if np.linalg.norm(grasp_dir) < 0.1:  # Handle parallel case\n                    grasp_dir = np.array([1, 0, 0])\n\n                grasp_dir = grasp_dir / np.linalg.norm(grasp_dir)\n\n                # Create grasp candidate\n                candidate = {\n                    \'position\': point,\n                    \'approach_direction\': approach_dir,\n                    \'grasp_direction\': grasp_dir,\n                    \'quality\': 0.0\n                }\n\n                # Evaluate grasp quality\n                candidate[\'quality\'] = self.evaluate_grasp_quality(\n                    object_points, candidate\n                )\n\n                candidates.append(candidate)\n\n        return candidates\n\n    def sample_surface_points(self, object_points: np.ndarray,\n                            num_points: int) -> List[np.ndarray]:\n        """\n        Sample points on the object surface for potential grasp locations\n        """\n        # For this example, we\'ll randomly sample points from the point cloud\n        # In practice, this would use more sophisticated surface sampling\n        if len(object_points) <= num_points:\n            return [np.array(p) for p in object_points]\n\n        indices = np.random.choice(len(object_points), num_points, replace=False)\n        return [np.array(object_points[i]) for i in indices]\n\n    def evaluate_grasp_quality(self, object_points: np.ndarray,\n                             grasp_candidate: dict) -> float:\n        """\n        Evaluate the quality of a grasp candidate based on geometric properties\n        """\n        pos = grasp_candidate[\'position\']\n        approach = grasp_candidate[\'approach_direction\']\n        grasp_dir = grasp_candidate[\'grasp_direction\']\n\n        # Check if approach direction is free of obstacles\n        # (In practice, this would check against environment geometry)\n        approach_clear = self.is_approach_clear(object_points, pos, approach)\n\n        # Calculate grasp width (distance between potential contact points)\n        grasp_width = self.estimate_grasp_width(object_points, pos, grasp_dir)\n\n        # Calculate geometric properties for quality assessment\n        quality = 0.0\n\n        if approach_clear and 0.01 < grasp_width < 0.2:  # Reasonable grasp width\n            # Prefer grasps at object edges or features\n            edge_score = self.calculate_edge_score(object_points, pos)\n            quality = 0.3 * approach_clear + 0.4 * edge_score + 0.3 * (1.0 / grasp_width)\n\n        return min(quality, 1.0)  # Clamp to [0, 1]\n\n    def is_approach_clear(self, object_points: np.ndarray,\n                         position: np.ndarray, approach_dir: np.ndarray) -> bool:\n        """\n        Check if approach direction is clear of object geometry\n        """\n        # Sample points along the approach direction\n        for dist in np.linspace(0.01, 0.05, 5):  # Check 1-5cm from surface\n            test_point = position + approach_dir * dist\n            # Find closest point on object\n            distances = np.linalg.norm(object_points - test_point, axis=1)\n            if np.min(distances) < 0.01:  # Within 1cm\n                return False  # Approach blocked\n\n        return True\n\n    def estimate_grasp_width(self, object_points: np.ndarray,\n                           position: np.ndarray, grasp_dir: np.ndarray) -> float:\n        """\n        Estimate the width of the object in the grasp direction\n        """\n        # Project points along grasp direction\n        projections = np.dot(object_points, grasp_dir)\n        min_proj = np.min(projections)\n        max_proj = np.max(projections)\n\n        return max_proj - min_proj\n\n    def calculate_edge_score(self, object_points: np.ndarray,\n                           position: np.ndarray) -> float:\n        """\n        Calculate score based on how "edge-like" the grasp location is\n        """\n        # Find neighboring points\n        distances = np.linalg.norm(object_points - position, axis=1)\n        neighbors = object_points[distances < 0.02]  # Points within 2cm\n\n        if len(neighbors) < 3:\n            return 0.0\n\n        # Calculate local curvature/surface properties\n        # Simple approach: look for regions with high point density variation\n        cov_matrix = np.cov(neighbors.T)\n        eigenvalues = np.linalg.eigvals(cov_matrix)\n        eigenvalues = np.sort(eigenvalues)\n\n        # Prefer locations with one small eigenvalue (planar) or all similar (corner)\n        if eigenvalues[0] < 0.1 * eigenvalues[2]:  # Planar region\n            return 0.8\n        elif abs(eigenvalues[0] - eigenvalues[2]) < 0.1:  # Corner-like\n            return 0.9\n        else:  # In-between\n            return 0.5\n\n    def select_best_grasp(self, candidates: List[dict],\n                         min_quality: float = 0.5) -> Optional[dict]:\n        """\n        Select the best grasp from candidates based on quality\n        """\n        valid_candidates = [c for c in candidates if c[\'quality\'] >= min_quality]\n        if not valid_candidates:\n            return None\n\n        # Return the candidate with highest quality\n        return max(valid_candidates, key=lambda x: x[\'quality\'])\n\n# Example usage\ndef grasp_planning_example():\n    planner = GraspPlanner()\n\n    # Create a sample object point cloud (a simple cube for demonstration)\n    cube_points = []\n    for x in np.linspace(-0.05, 0.05, 10):\n        for y in np.linspace(-0.05, 0.05, 10):\n            for z in np.linspace(-0.05, 0.05, 10):\n                # Only include surface points to make it more realistic\n                if (abs(x) == 0.05 or abs(y) == 0.05 or abs(z) == 0.05):\n                    cube_points.append([x, y, z])\n\n    object_points = np.array(cube_points)\n\n    # Generate grasp candidates\n    candidates = planner.generate_grasp_candidates(object_points, num_candidates=100)\n\n    # Select best grasp\n    best_grasp = planner.select_best_grasp(candidates)\n\n    if best_grasp:\n        print(f"Best grasp found:")\n        print(f"  Position: {best_grasp[\'position\']}")\n        print(f"  Approach: {best_grasp[\'approach_direction\']}")\n        print(f"  Quality: {best_grasp[\'quality\']:.3f}")\n    else:\n        print("No suitable grasp found")\n\nif __name__ == "__main__":\n    grasp_planning_example()\n'})}),"\n",(0,t.jsx)(e.h3,{id:"example-grasp-quality-evaluation-metrics",children:"Example: Grasp Quality Evaluation Metrics"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:'import numpy as np\nfrom typing import List, Tuple\nimport math\n\nclass GraspQualityEvaluator:\n    """Evaluates grasp quality using multiple metrics"""\n\n    def __init__(self, friction_coeff=0.8):\n        self.friction_coeff = friction_coeff\n\n    def force_closure_metric(self, contact_points: List[np.ndarray],\n                           contact_normals: List[np.ndarray]) -> float:\n        """\n        Evaluate force closure - ability to resist arbitrary wrenches\n        """\n        if len(contact_points) < 2:\n            return 0.0\n\n        # For 2D case: check if contact normals point toward each other\n        if len(contact_points[0]) == 2:\n            # Calculate angle between contact normals\n            n1 = contact_normals[0] / np.linalg.norm(contact_normals[0])\n            n2 = contact_normals[1] / np.linalg.norm(contact_normals[1])\n\n            # Check if normals point toward each other (angle > 90\xb0)\n            dot_product = np.dot(n1, n2)\n            if dot_product < -0.1:  # Pointing roughly toward each other\n                return 1.0\n            else:\n                return 0.0\n\n        # For 3D case: more complex force closure analysis\n        # This is a simplified version - full analysis requires polyhedral cone computation\n        if len(contact_points) >= 4:\n            # Multiple contacts increase chance of force closure\n            return min(1.0, len(contact_points) * 0.25)\n        else:\n            return 0.0\n\n    def grasp_width_metric(self, grasp_width: float,\n                          min_width: float = 0.01,\n                          max_width: float = 0.15) -> float:\n        """\n        Evaluate grasp width appropriateness\n        """\n        if min_width <= grasp_width <= max_width:\n            # Score based on how close to optimal width\n            optimal = (min_width + max_width) / 2\n            deviation = abs(grasp_width - optimal) / (max_width - min_width)\n            return max(0.0, 1.0 - deviation)\n        else:\n            return 0.0\n\n    def contact_stability_metric(self, object_points: np.ndarray,\n                               contact_points: List[np.ndarray],\n                               grasp_axis: np.ndarray) -> float:\n        """\n        Evaluate stability based on contact distribution\n        """\n        if len(contact_points) < 2:\n            return 0.0\n\n        # Calculate how well contacts distribute along grasp axis\n        projections = [np.dot(cp, grasp_axis) for cp in contact_points]\n        min_proj, max_proj = min(projections), max(projections)\n\n        # Prefer contacts that span a reasonable distance\n        span = max_proj - min_proj\n        if span > 0.02:  # At least 2cm span\n            return min(1.0, span / 0.1)  # Cap at 10cm span\n        else:\n            return 0.5 * span / 0.02  # Lower score for small span\n\n    def wrench_space_metric(self, contact_points: List[np.ndarray],\n                          contact_forces: List[np.ndarray]) -> float:\n        """\n        Evaluate the wrench space that can be resisted by the grasp\n        """\n        # Simplified metric based on contact distribution\n        if len(contact_points) < 2:\n            return 0.0\n\n        # Calculate the volume of the grasp wrench space (simplified)\n        # This would be more complex in a real implementation\n        total_force_magnitude = sum(np.linalg.norm(f) for f in contact_forces)\n        return min(1.0, total_force_magnitude / 100.0)  # Normalize\n\n    def evaluate_comprehensive_grasp_quality(self, object_points: np.ndarray,\n                                           contact_points: List[np.ndarray],\n                                           contact_normals: List[np.ndarray],\n                                           grasp_width: float,\n                                           grasp_axis: np.ndarray) -> dict:\n        """\n        Evaluate comprehensive grasp quality using multiple metrics\n        """\n        metrics = {}\n\n        # Calculate individual metrics\n        metrics[\'force_closure\'] = self.force_closure_metric(contact_points, contact_normals)\n        metrics[\'grasp_width\'] = self.grasp_width_metric(grasp_width)\n        metrics[\'contact_stability\'] = self.contact_stability_metric(\n            object_points, contact_points, grasp_axis\n        )\n\n        # Create dummy contact forces for wrench space metric\n        dummy_forces = [n * 10.0 for n in contact_normals]  # 10N in normal direction\n        metrics[\'wrench_space\'] = self.wrench_space_metric(contact_points, dummy_forces)\n\n        # Calculate overall quality as weighted average\n        weights = {\n            \'force_closure\': 0.4,\n            \'grasp_width\': 0.2,\n            \'contact_stability\': 0.2,\n            \'wrench_space\': 0.2\n        }\n\n        overall_quality = sum(metrics[metric] * weights[metric] for metric in weights)\n\n        return {\n            \'metrics\': metrics,\n            \'weights\': weights,\n            \'overall_quality\': overall_quality\n        }\n\n# Example usage\ndef quality_evaluation_example():\n    evaluator = GraspQualityEvaluator()\n\n    # Example grasp configuration\n    object_points = np.random.rand(100, 3) * 0.1  # Random object points\n    contact_points = [\n        np.array([0.02, 0.0, 0.0]),\n        np.array([-0.02, 0.0, 0.0])\n    ]\n    contact_normals = [\n        np.array([-1.0, 0.0, 0.0]),  # Pointing inward\n        np.array([1.0, 0.0, 0.0])    # Pointing inward\n    ]\n    grasp_width = 0.04  # 4cm\n    grasp_axis = np.array([1.0, 0.0, 0.0])\n\n    quality_result = evaluator.evaluate_comprehensive_grasp_quality(\n        object_points, contact_points, contact_normals, grasp_width, grasp_axis\n    )\n\n    print("Grasp Quality Evaluation:")\n    for metric, value in quality_result[\'metrics\'].items():\n        print(f"  {metric}: {value:.3f}")\n\n    print(f"Overall Quality: {quality_result[\'overall_quality\']:.3f}")\n\nif __name__ == "__main__":\n    quality_evaluation_example()\n'})}),"\n",(0,t.jsx)(e.h3,{id:"example-integration-with-robot-kinematics",children:"Example: Integration with Robot Kinematics"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:"import numpy as np\nfrom typing import List, Tuple, Optional\nfrom dataclasses import dataclass\n\n@dataclass\nclass GraspPose:\n    \"\"\"Represents a complete grasp pose with approach, pre-grasp, and grasp positions\"\"\"\n    approach_pose: np.ndarray  # 3D position + orientation\n    pre_grasp_pose: np.ndarray\n    grasp_pose: np.ndarray\n    grasp_quality: float\n    grasp_type: str  # 'power', 'pinch', 'suction', etc.\n\nclass KinematicGraspPlanner:\n    \"\"\"Grasp planner that considers robot kinematics and constraints\"\"\"\n\n    def __init__(self, robot_workspace_limits: dict):\n        self.workspace_limits = robot_workspace_limits\n        self.max_joint_velocity = 1.0  # rad/s\n        self.max_joint_torque = 100.0  # Nm\n\n    def plan_grasp_with_kinematics(self, object_position: np.ndarray,\n                                 object_orientation: np.ndarray,\n                                 grasp_candidate: dict) -> Optional[GraspPose]:\n        \"\"\"\n        Plan grasp poses considering robot kinematics and workspace constraints\n        \"\"\"\n        # Calculate grasp pose based on object pose and grasp direction\n        grasp_pose = self.calculate_grasp_pose(object_position, object_orientation, grasp_candidate)\n\n        # Check if grasp pose is within workspace\n        if not self.is_in_workspace(grasp_pose[:3]):  # Check position only\n            return None\n\n        # Calculate approach pose (offset along approach direction)\n        approach_offset = grasp_candidate['approach_direction'] * 0.1  # 10cm approach\n        approach_pose = grasp_pose.copy()\n        approach_pose[:3] += approach_offset\n\n        # Check if approach pose is also within workspace\n        if not self.is_in_workspace(approach_pose[:3]):\n            # Try alternative approach direction\n            alt_approach = grasp_candidate['approach_direction'] * -0.1\n            approach_pose[:3] = grasp_pose[:3] + alt_approach\n            if not self.is_in_workspace(approach_pose[:3]):\n                return None\n\n        # Calculate pre-grasp pose (slightly before grasp)\n        pre_grasp_pose = grasp_pose.copy()\n        pre_grasp_offset = grasp_candidate['approach_direction'] * 0.02  # 2cm before grasp\n        pre_grasp_pose[:3] += pre_grasp_offset\n\n        # Check joint limits would be satisfied (simplified check)\n        if not self.would_exceed_joint_limits(approach_pose, grasp_pose):\n            return GraspPose(\n                approach_pose=approach_pose,\n                pre_grasp_pose=pre_grasp_pose,\n                grasp_pose=grasp_pose,\n                grasp_quality=grasp_candidate['quality'],\n                grasp_type=self.determine_grasp_type(grasp_candidate)\n            )\n\n        return None\n\n    def calculate_grasp_pose(self, obj_pos: np.ndarray, obj_rot: np.ndarray,\n                           grasp_candidate: dict) -> np.ndarray:\n        \"\"\"\n        Calculate full 6D grasp pose from object pose and grasp parameters\n        \"\"\"\n        # Calculate position: object position + offset in grasp direction\n        grasp_pos = obj_pos + grasp_candidate['position_offset']\n\n        # Calculate orientation: align gripper with grasp direction\n        grasp_dir = grasp_candidate['grasp_direction']\n        approach_dir = grasp_candidate['approach_direction']\n\n        # Create rotation matrix from approach and grasp directions\n        z_axis = approach_dir / np.linalg.norm(approach_dir)\n        y_axis = grasp_dir / np.linalg.norm(grasp_dir)\n        x_axis = np.cross(y_axis, z_axis)\n        x_axis = x_axis / np.linalg.norm(x_axis)\n        y_axis = np.cross(z_axis, x_axis)  # Recompute to ensure orthogonality\n\n        rotation_matrix = np.column_stack([x_axis, y_axis, z_axis])\n\n        # Convert to quaternion (simplified)\n        # In practice, use proper quaternion conversion\n        pose = np.zeros(7)  # [x, y, z, qx, qy, qz, qw]\n        pose[:3] = grasp_pos\n\n        # Convert rotation matrix to quaternion\n        trace = np.trace(rotation_matrix)\n        if trace > 0:\n            s = 0.5 / np.sqrt(trace + 1.0)\n            pose[6] = 0.25 / s  # w\n            pose[3] = (rotation_matrix[2, 1] - rotation_matrix[1, 2]) * s  # x\n            pose[4] = (rotation_matrix[0, 2] - rotation_matrix[2, 0]) * s  # y\n            pose[5] = (rotation_matrix[1, 0] - rotation_matrix[0, 1]) * s  # z\n        else:\n            if rotation_matrix[0, 0] > rotation_matrix[1, 1] and rotation_matrix[0, 0] > rotation_matrix[2, 2]:\n                s = 2.0 * np.sqrt(1.0 + rotation_matrix[0, 0] - rotation_matrix[1, 1] - rotation_matrix[2, 2])\n                pose[3] = 0.25 * s\n                pose[4] = (rotation_matrix[0, 1] + rotation_matrix[1, 0]) / s\n                pose[5] = (rotation_matrix[0, 2] + rotation_matrix[2, 0]) / s\n                pose[6] = (rotation_matrix[2, 1] - rotation_matrix[1, 2]) / s\n            elif rotation_matrix[1, 1] > rotation_matrix[2, 2]:\n                s = 2.0 * np.sqrt(1.0 + rotation_matrix[1, 1] - rotation_matrix[0, 0] - rotation_matrix[2, 2])\n                pose[3] = (rotation_matrix[0, 1] + rotation_matrix[1, 0]) / s\n                pose[4] = 0.25 * s\n                pose[5] = (rotation_matrix[1, 2] + rotation_matrix[2, 1]) / s\n                pose[6] = (rotation_matrix[0, 2] - rotation_matrix[2, 0]) / s\n            else:\n                s = 2.0 * np.sqrt(1.0 + rotation_matrix[2, 2] - rotation_matrix[0, 0] - rotation_matrix[1, 1])\n                pose[3] = (rotation_matrix[0, 2] + rotation_matrix[2, 0]) / s\n                pose[4] = (rotation_matrix[1, 2] + rotation_matrix[2, 1]) / s\n                pose[5] = 0.25 * s\n                pose[6] = (rotation_matrix[1, 0] - rotation_matrix[0, 1]) / s\n\n        return pose\n\n    def is_in_workspace(self, position: np.ndarray) -> bool:\n        \"\"\"Check if position is within robot workspace\"\"\"\n        x, y, z = position\n        limits = self.workspace_limits\n        return (limits['x_min'] <= x <= limits['x_max'] and\n                limits['y_min'] <= y <= limits['y_max'] and\n                limits['z_min'] <= z <= limits['z_max'])\n\n    def would_exceed_joint_limits(self, start_pose: np.ndarray,\n                                end_pose: np.ndarray) -> bool:\n        \"\"\"Check if trajectory between poses would exceed joint limits\"\"\"\n        # Simplified check - in practice, this would involve inverse kinematics\n        # and trajectory verification\n        distance = np.linalg.norm(end_pose[:3] - start_pose[:3])\n        # Assume this distance can be achieved within joint limits for this example\n        return False\n\n    def determine_grasp_type(self, grasp_candidate: dict) -> str:\n        \"\"\"Determine appropriate grasp type based on object and grasp properties\"\"\"\n        # This would use more sophisticated logic in practice\n        grasp_width = grasp_candidate.get('grasp_width', 0.1)\n\n        if grasp_width < 0.03:  # Small objects\n            return 'pinch'\n        elif grasp_width < 0.08:  # Medium objects\n            return 'power'\n        else:  # Large objects\n            return 'enveloping'\n\n# Example usage\ndef kinematic_integration_example():\n    # Define robot workspace limits\n    workspace_limits = {\n        'x_min': -1.0, 'x_max': 1.0,\n        'y_min': -1.0, 'y_max': 1.0,\n        'z_min': 0.0,  'z_max': 1.5\n    }\n\n    planner = KinematicGraspPlanner(workspace_limits)\n\n    # Example object and grasp candidate\n    object_pos = np.array([0.5, 0.0, 0.2])\n    object_rot = np.eye(3)  # Identity rotation\n\n    grasp_candidate = {\n        'position_offset': np.array([0.0, 0.0, 0.0]),\n        'grasp_direction': np.array([0.0, 1.0, 0.0]),\n        'approach_direction': np.array([0.0, 0.0, 1.0]),\n        'quality': 0.8,\n        'grasp_width': 0.05\n    }\n\n    grasp_pose = planner.plan_grasp_with_kinematics(object_pos, object_rot, grasp_candidate)\n\n    if grasp_pose:\n        print(f\"Valid grasp planned:\")\n        print(f\"  Approach: [{grasp_pose.approach_pose[:3]}]\")\n        print(f\"  Grasp: [{grasp_pose.grasp_pose[:3]}]\")\n        print(f\"  Quality: {grasp_pose.grasp_quality:.3f}\")\n        print(f\"  Type: {grasp_pose.grasp_type}\")\n    else:\n        print(\"Could not plan valid grasp within kinematic constraints\")\n\nif __name__ == \"__main__\":\n    kinematic_integration_example()\n"})}),"\n",(0,t.jsx)(e.h2,{id:"practical-notes",children:"Practical Notes"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"Consider object material properties and fragility in grasp planning"}),"\n",(0,t.jsx)(e.li,{children:"Validate grasp plans with physical simulation before execution"}),"\n",(0,t.jsx)(e.li,{children:"Implement regrasping strategies for failed grasp attempts"}),"\n",(0,t.jsx)(e.li,{children:"Account for sensor noise and uncertainty in object pose estimation"}),"\n",(0,t.jsx)(e.li,{children:"Test grasp planning under various environmental conditions"}),"\n",(0,t.jsx)(e.li,{children:"Plan for computational efficiency in real-time applications"}),"\n",(0,t.jsx)(e.li,{children:"Implement safety checks to prevent damage to objects or robot"}),"\n"]}),"\n",(0,t.jsx)(e.h2,{id:"summary",children:"Summary"}),"\n",(0,t.jsx)(e.p,{children:"Grasp planning is a complex task that requires understanding of object geometry, robot kinematics, and physical interactions. Successful grasp planning systems must balance multiple objectives including grasp stability, kinematic feasibility, and task requirements. Modern approaches combine analytical methods with learning-based techniques to handle diverse objects and scenarios in real-world manipulation tasks."}),"\n",(0,t.jsx)(e.h2,{id:"glossary",children:"Glossary"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Grasp Planning"}),": Process of determining how to grasp an object with a robot hand"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Force Closure"}),": Grasp condition where applied forces can resist arbitrary external wrenches"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Form Closure"}),": Grasp relying on geometric constraints rather than friction forces"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Grasp Wrench Space"}),": Set of external forces and torques a grasp can resist"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Contact Points"}),": Locations where robot fingers make contact with object"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Approach Direction"}),": Direction robot approaches object before grasping"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Grasp Quality Metric"}),": Quantitative measure of grasp stability and effectiveness"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Antipodal Grasp"}),": Grasp with contact points on opposite sides of object"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Pinch Grasp"}),": Precision grasp using fingertips for small objects"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Power Grasp"}),": Grasp using fingers wrapped around object for strength"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Enveloping Grasp"}),": Grasp wrapping around object with multiple contact points"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Grasp Stability"}),": Ability of grasp to maintain contact under disturbances"]}),"\n"]}),"\n",(0,t.jsx)(e.h2,{id:"quick-quiz",children:"Quick Quiz"}),"\n",(0,t.jsxs)(e.ol,{children:["\n",(0,t.jsxs)(e.li,{children:["\n",(0,t.jsx)(e.p,{children:"What is the main difference between force closure and form closure grasps?\nA) Force closure uses more contact points\nB) Force closure relies on friction and applied forces, form closure on geometric constraints\nC) Form closure is only for spherical objects\nD) There is no difference between them"}),"\n"]}),"\n",(0,t.jsxs)(e.li,{children:["\n",(0,t.jsx)(e.p,{children:'What does "grasp wrench space" refer to?\nA) The physical space around the object\nB) The set of external forces and torques a grasp can resist\nC) The workspace of the robot arm\nD) The area where grasping is possible'}),"\n"]}),"\n",(0,t.jsxs)(e.li,{children:["\n",(0,t.jsx)(e.p,{children:"Which grasp type is typically used for precision manipulation of small objects?\nA) Power grasp\nB) Enveloping grasp\nC) Pinch grasp\nD) Suction grasp"}),"\n"]}),"\n",(0,t.jsxs)(e.li,{children:["\n",(0,t.jsx)(e.p,{children:"What is an antipodal grasp?\nA) A grasp with contact points on the same side\nB) A grasp with contact points on opposite sides of the object\nC) A grasp using only one finger\nD) A grasp that cannot resist forces"}),"\n"]}),"\n",(0,t.jsxs)(e.li,{children:["\n",(0,t.jsx)(e.p,{children:"Why is it important to consider robot kinematics in grasp planning?\nA) To make the robot move faster\nB) To ensure the robot can physically reach the planned grasp pose\nC) To reduce computational requirements\nD) To improve sensor accuracy"}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(e.p,{children:(0,t.jsx)(e.strong,{children:"Answers:"})}),"\n",(0,t.jsxs)(e.ol,{children:["\n",(0,t.jsx)(e.li,{children:"B) Force closure relies on friction and applied forces, form closure on geometric constraints"}),"\n",(0,t.jsx)(e.li,{children:"B) The set of external forces and torques a grasp can resist"}),"\n",(0,t.jsx)(e.li,{children:"C) Pinch grasp"}),"\n",(0,t.jsx)(e.li,{children:"B) A grasp with contact points on opposite sides of the object"}),"\n",(0,t.jsx)(e.li,{children:"B) To ensure the robot can physically reach the planned grasp pose"}),"\n"]})]})}function d(n={}){const{wrapper:e}={...(0,r.R)(),...n.components};return e?(0,t.jsx)(e,{...n,children:(0,t.jsx)(l,{...n})}):l(n)}},8453:(n,e,a)=>{a.d(e,{R:()=>s,x:()=>o});var i=a(6540);const t={},r=i.createContext(t);function s(n){const e=i.useContext(r);return i.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function o(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(t):n.components||t:s(n.components),i.createElement(r.Provider,{value:e},n.children)}}}]);