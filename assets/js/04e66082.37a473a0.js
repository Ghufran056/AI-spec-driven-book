"use strict";(globalThis.webpackChunkai_driven_book=globalThis.webpackChunkai_driven_book||[]).push([[5442],{3502:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>l,contentTitle:()=>r,default:()=>h,frontMatter:()=>a,metadata:()=>t,toc:()=>c});const t=JSON.parse('{"id":"chapter2/2.7-segmentation-pose-estimation-depth-estimation","title":"Segmentation, Pose Estimation, Depth Estimation","description":"Learning Objectives","source":"@site/docs/chapter2/2.7-segmentation-pose-estimation-depth-estimation.mdx","sourceDirName":"chapter2","slug":"/chapter2/2.7-segmentation-pose-estimation-depth-estimation","permalink":"/AI-spec-driven-book/docs/chapter2/2.7-segmentation-pose-estimation-depth-estimation","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/chapter2/2.7-segmentation-pose-estimation-depth-estimation.mdx","tags":[],"version":"current","frontMatter":{"id":"2.7-segmentation-pose-estimation-depth-estimation","title":"Segmentation, Pose Estimation, Depth Estimation","sidebar_label":"2.7 - Segmentation, Pose Estimation, Depth Estimation"},"sidebar":"tutorialSidebar","previous":{"title":"2.6 - Computer Vision Basics (CV)","permalink":"/AI-spec-driven-book/docs/chapter2/2.6-computer-vision-basics"},"next":{"title":"2.8 - Perception for Manipulation Tasks","permalink":"/AI-spec-driven-book/docs/chapter2/2.8-perception-for-manipulation-tasks"}}');var s=i(4848),o=i(8453);const a={id:"2.7-segmentation-pose-estimation-depth-estimation",title:"Segmentation, Pose Estimation, Depth Estimation",sidebar_label:"2.7 - Segmentation, Pose Estimation, Depth Estimation"},r="Segmentation, Pose Estimation, Depth Estimation",l={},c=[{value:"Learning Objectives",id:"learning-objectives",level:2},{value:"Introduction",id:"introduction",level:2},{value:"How it Works",id:"how-it-works",level:2},{value:"1. Semantic Segmentation",id:"1-semantic-segmentation",level:3},{value:"2. Instance Segmentation",id:"2-instance-segmentation",level:3},{value:"3. Object Pose Estimation",id:"3-object-pose-estimation",level:3},{value:"4. Depth Estimation from Stereo",id:"4-depth-estimation-from-stereo",level:3},{value:"5. Monocular Depth Estimation",id:"5-monocular-depth-estimation",level:3},{value:"6. 3D Reconstruction",id:"6-3d-reconstruction",level:3},{value:"Simple Diagrams",id:"simple-diagrams",level:2},{value:"Real-world Examples",id:"real-world-examples",level:2},{value:"Warehouse Automation",id:"warehouse-automation",level:3},{value:"Autonomous Vehicles",id:"autonomous-vehicles",level:3},{value:"Augmented Reality",id:"augmented-reality",level:3},{value:"Depth Estimation and Stereo Disparity",id:"depth-estimation-and-stereo-disparity",level:3},{value:"Summary",id:"summary",level:2},{value:"Glossary",id:"glossary",level:2},{value:"Quick Quiz",id:"quick-quiz",level:2}];function d(e){const n={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,o.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.header,{children:(0,s.jsx)(n.h1,{id:"segmentation-pose-estimation-depth-estimation",children:"Segmentation, Pose Estimation, Depth Estimation"})}),"\n",(0,s.jsx)(n.h2,{id:"learning-objectives",children:"Learning Objectives"}),"\n",(0,s.jsx)(n.p,{children:"By the end of this lesson, you will be able to:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Understand image segmentation and its role in robotic perception"}),"\n",(0,s.jsx)(n.li,{children:"Explain how robots estimate the pose (position and orientation) of objects"}),"\n",(0,s.jsx)(n.li,{children:"Describe depth estimation techniques and their applications"}),"\n",(0,s.jsx)(n.li,{children:"Identify practical uses of these perception techniques in robotics"}),"\n",(0,s.jsx)(n.li,{children:"Recognize the relationship between stereo disparity and depth estimation"}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"introduction",children:"Introduction"}),"\n",(0,s.jsx)(n.p,{children:"Advanced perception techniques like segmentation, pose estimation, and depth estimation enable robots to understand the 3D structure of their environment and the spatial relationships between objects. Image segmentation involves partitioning an image into multiple segments to simplify analysis. Pose estimation determines the position and orientation of objects relative to the camera or robot. Depth estimation provides distance information for each pixel in an image, creating a 3D understanding from 2D visual data."}),"\n",(0,s.jsx)(n.p,{children:"These techniques are fundamental to sophisticated robotic applications like manipulation, navigation, and human-robot interaction. Together, they provide robots with detailed spatial understanding that enables them to interact safely and effectively with complex environments. Depth estimation, in particular, can be achieved through stereo vision by analyzing the disparity between left and right camera images."}),"\n",(0,s.jsx)(n.h2,{id:"how-it-works",children:"How it Works"}),"\n",(0,s.jsx)(n.h3,{id:"1-semantic-segmentation",children:"1. Semantic Segmentation"}),"\n",(0,s.jsx)(n.p,{children:"The process of assigning a class label to each pixel in an image, creating regions that correspond to different object categories (e.g., road, car, pedestrian). This helps robots understand what objects are present in a scene."}),"\n",(0,s.jsx)(n.h3,{id:"2-instance-segmentation",children:"2. Instance Segmentation"}),"\n",(0,s.jsx)(n.p,{children:"A more detailed form of segmentation that not only identifies object categories but also distinguishes between different instances of the same category (e.g., identifying each individual car in a parking lot)."}),"\n",(0,s.jsx)(n.h3,{id:"3-object-pose-estimation",children:"3. Object Pose Estimation"}),"\n",(0,s.jsx)(n.p,{children:"Determining the 6D pose (3D position and 3D orientation) of objects using visual features, geometric models, or learning-based approaches. This is crucial for robotic manipulation tasks."}),"\n",(0,s.jsx)(n.h3,{id:"4-depth-estimation-from-stereo",children:"4. Depth Estimation from Stereo"}),"\n",(0,s.jsx)(n.p,{children:"Calculating depth by finding corresponding points in left and right camera images and using the disparity (difference in position) to compute distance using triangulation principles."}),"\n",(0,s.jsx)(n.h3,{id:"5-monocular-depth-estimation",children:"5. Monocular Depth Estimation"}),"\n",(0,s.jsx)(n.p,{children:"Estimating depth from a single camera image using learned models that infer depth based on visual cues like perspective, texture gradients, and object size."}),"\n",(0,s.jsx)(n.h3,{id:"6-3d-reconstruction",children:"6. 3D Reconstruction"}),"\n",(0,s.jsx)(n.p,{children:"Building a three-dimensional representation of objects or scenes from multiple images or depth information, enabling robots to understand spatial relationships."}),"\n",(0,s.jsx)(n.h2,{id:"simple-diagrams",children:"Simple Diagrams"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"Image Segmentation:\n\nInput Image:        Semantic Segmentation:    Instance Segmentation:\n+-------------+     +-------------+           +-------------+\n|  Car    Car |     |  1    1    |           |  1    2    |\n|  Road  Tree |  \u2192  |  0    2    |       \u2192   |  0    3    |\n|  Car  Grass |     |  1    3    |           |  4    5    |\n+-------------+     +-------------+           +-------------+\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"Pose Estimation:\n\n3D Object Model\n      *\n     /|\\\n    / | \\\n   /  |  \\\n  *---*---* \u2192 2D Image with estimated pose\n   \\  |  /      (position, orientation)\n    \\ | /\n     \\|/\n      *\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"Stereo Disparity to Depth:\n\nLeft Image:     [Object]---------[Object]\n                * * *             * * *\n                    \u2190 Disparity \u2192\nRight Image:    [Object]---------[Object]\n                   * * *             * * *\n\nDepth = (Baseline \xd7 Focal Length) / Disparity\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"Depth Estimation Pipeline:\n\nStereo Images \u2192 Feature Matching \u2192 Disparity Map \u2192 Depth Map \u2192 3D Coordinates\n"})}),"\n",(0,s.jsx)(n.h2,{id:"real-world-examples",children:"Real-world Examples"}),"\n",(0,s.jsx)(n.h3,{id:"warehouse-automation",children:"Warehouse Automation"}),"\n",(0,s.jsx)(n.p,{children:"Robots use segmentation to identify individual items on conveyor belts and estimate their poses for precise grasping. Depth estimation helps determine the exact position of objects in 3D space, enabling reliable manipulation."}),"\n",(0,s.jsx)(n.h3,{id:"autonomous-vehicles",children:"Autonomous Vehicles"}),"\n",(0,s.jsx)(n.p,{children:"Self-driving cars use segmentation to identify drivable areas, other vehicles, pedestrians, and obstacles. Pose estimation helps track the movement and predicted paths of other vehicles and pedestrians."}),"\n",(0,s.jsx)(n.h3,{id:"augmented-reality",children:"Augmented Reality"}),"\n",(0,s.jsx)(n.p,{children:"AR systems use segmentation to identify surfaces and objects in the environment, then estimate their poses to correctly place virtual objects that interact naturally with the real world."}),"\n",(0,s.jsx)(n.h3,{id:"depth-estimation-and-stereo-disparity",children:"Depth Estimation and Stereo Disparity"}),"\n",(0,s.jsx)(n.p,{children:"Modern smartphones use stereo cameras to create depth maps for portrait mode photography. Robotics applications use stereo disparity to understand the 3D structure of scenes for navigation and manipulation tasks. By analyzing the difference in position of objects between left and right camera images, robots can calculate accurate depth information for each point in the scene."}),"\n",(0,s.jsx)(n.h2,{id:"summary",children:"Summary"}),"\n",(0,s.jsx)(n.p,{children:"Segmentation, pose estimation, and depth estimation are advanced perception techniques that provide robots with detailed spatial understanding of their environment. Segmentation helps robots identify and separate different objects, pose estimation determines object positions and orientations, and depth estimation provides crucial 3D spatial information. These techniques enable sophisticated robotic applications like precise manipulation, safe navigation, and natural human-robot interaction. The combination of stereo vision and disparity analysis provides accurate depth information that is essential for many robotic tasks."}),"\n",(0,s.jsx)(n.h2,{id:"glossary",children:"Glossary"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Image Segmentation"}),": Partitioning an image into multiple segments to simplify analysis"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Semantic Segmentation"}),": Assigning class labels to each pixel based on object category"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Instance Segmentation"}),": Distinguishing between different instances of the same object category"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Pose Estimation"}),": Determining the 6D position and orientation of objects in 3D space"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Depth Estimation"}),": Calculating distance information for pixels in an image"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Stereo Disparity"}),": The difference in position of objects between left and right stereo images"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"3D Reconstruction"}),": Building three-dimensional representations from multiple images"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Triangulation"}),": Determining distance using the geometric relationship between cameras and objects"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"6D Pose"}),": The 3D position (x, y, z) and 3D orientation (roll, pitch, yaw) of an object"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Disparity Map"}),": A 2D image where pixel values represent the difference in position between stereo images"]}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"quick-quiz",children:"Quick Quiz"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"What is the main difference between semantic and instance segmentation?\nA) Semantic segmentation is faster than instance segmentation\nB) Instance segmentation distinguishes between different instances of the same category\nC) Semantic segmentation uses more colors than instance segmentation\nD) There is no difference between them"}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"What does 6D pose refer to?\nA) Six-dimensional space\nB) The 3D position and 3D orientation of an object\nC) Six different types of poses\nD) Pose estimation with six cameras"}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"How is depth calculated from stereo disparity?\nA) Depth = Baseline + Focal Length + Disparity\nB) Depth = (Baseline \xd7 Focal Length) / Disparity\nC) Depth = Disparity / (Baseline \xd7 Focal Length)\nD) Depth = Baseline \xd7 Disparity \xd7 Focal Length"}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"What is stereo disparity?\nA) The color difference between two images\nB) The difference in position of objects between left and right stereo images\nC) The brightness difference between two images\nD) The size difference between two images"}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"Which of the following is NOT a type of segmentation mentioned in this lesson?\nA) Semantic segmentation\nB) Instance segmentation\nC) Temporal segmentation\nD) Both A and B"}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Answers:"})}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsx)(n.li,{children:"B) Instance segmentation distinguishes between different instances of the same category"}),"\n",(0,s.jsx)(n.li,{children:"B) The 3D position and 3D orientation of an object"}),"\n",(0,s.jsx)(n.li,{children:"B) Depth = (Baseline \xd7 Focal Length) / Disparity"}),"\n",(0,s.jsx)(n.li,{children:"B) The difference in position of objects between left and right stereo images"}),"\n",(0,s.jsx)(n.li,{children:"C) Temporal segmentation"}),"\n"]})]})}function h(e={}){const{wrapper:n}={...(0,o.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(d,{...e})}):d(e)}},8453:(e,n,i)=>{i.d(n,{R:()=>a,x:()=>r});var t=i(6540);const s={},o=t.createContext(s);function a(e){const n=t.useContext(o);return t.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function r(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:a(e.components),t.createElement(o.Provider,{value:n},e.children)}}}]);